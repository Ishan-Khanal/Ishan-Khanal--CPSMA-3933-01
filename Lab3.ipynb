{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEBzV71VtfzZB//XvgAb4q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishan-Khanal/Ishan-Khanal--CPSMA-3933-01/blob/main/Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Assignment\n",
        "\n",
        "In this notebook, we will practice different types of regression analysis:\n",
        "1. Linear Regression on hockey data  \n",
        "2. Logistic Regression on Avengers data  \n",
        "3. A self-chosen regression with Olympic 100m dash data  \n",
        "\n",
        "We will analyze results, visualize the fits, and interpret the findings.\n"
      ],
      "metadata": {
        "id": "2XXWCHCE-BzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n"
      ],
      "metadata": {
        "id": "CgrSRvJ3-ECN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression: Goals vs Points\n",
        "\n",
        "We will load the hockey dataset and examine how goals (`G`) predict total points (`PTS`) using simple linear regression. Then, we expand to multiple regression using both goals (`G`) and assists (`A`) as predictors.\n"
      ],
      "metadata": {
        "id": "Y5yTHWbq-G99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/nurfnick/Data_Sets_For_Stats/master/CuratedDataSets/hockey.csv')\n",
        "\n",
        "X_single = df[['G']]\n",
        "y = df['PTS']\n",
        "\n",
        "model_single = LinearRegression().fit(X_single, y)\n",
        "y_pred_single = model_single.predict(X_single)\n",
        "\n",
        "plt.scatter(df['G'], y, label=\"Actual\")\n",
        "plt.plot(df['G'], y_pred_single, color=\"red\", label=\"Linear Fit\")\n",
        "plt.xlabel(\"Goals\")\n",
        "plt.ylabel(\"Points\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Single Regression R^2:\", r2_score(y, y_pred_single))\n"
      ],
      "metadata": {
        "id": "Bevx_JNt-Jls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple Regression: Goals and Assists vs Points\n"
      ],
      "metadata": {
        "id": "Y08SBDV0-TAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_multi = df[['G', 'A']]\n",
        "model_multi = LinearRegression().fit(X_multi, y)\n",
        "y_pred_multi = model_multi.predict(X_multi)\n",
        "\n",
        "print(\"Multiple Regression R^2:\", r2_score(y, y_pred_multi))\n",
        "print(\"Coefficients:\", model_multi.coef_)\n"
      ],
      "metadata": {
        "id": "aOFxB1c0-VL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**  \n",
        "The multiple regression including both goals and assists fits the data much better than goals alone. This is expected since points are directly derived from the sum of goals and assists.\n"
      ],
      "metadata": {
        "id": "0KSY8a2A-akX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression: Avengers Dataset\n",
        "\n",
        "Next, we use the Avengers dataset to predict whether a character has a recorded `Death1` (first death). Logistic regression is appropriate since the outcome is binary (YES/NO).\n"
      ],
      "metadata": {
        "id": "UOHOLJI8-iac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avengers = pd.read_csv('https://raw.githubusercontent.com/nurfnick/Data_Sets_For_Stats/master/CuratedDataSets/Avengers')\n",
        "avengers['Death1'] = avengers['Death1'].map({'YES':1,'NO':0})\n",
        "\n",
        "X = avengers[['Appearances']]\n",
        "y = avengers['Death1']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "log_model = LogisticRegression(max_iter=200).fit(X_train, y_train)\n",
        "y_pred = log_model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "TjkM4br4-oU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now predict probabilities for specific characters (e.g., Iron Man, Thor) by inputting their appearances.\n"
      ],
      "metadata": {
        "id": "JGpR7EPF-roh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char = np.array([[3000]])  # example appearances\n",
        "print(\"Predicted Probability of Death1:\", log_model.predict_proba(char))\n"
      ],
      "metadata": {
        "id": "cjPvASiN-uCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find Your Own Regression: Olympic 100m Dash\n",
        "\n",
        "We now examine Olympic 100m dash records. The idea is to see how the winning times have decreased over the years. We will fit a regression model to predict future Olympic records.\n"
      ],
      "metadata": {
        "id": "xBJfrR5s-z7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "olympics = pd.read_csv('https://raw.githubusercontent.com/nurfnick/Data_Sets_For_Stats/master/CuratedDataSets/100mOlympicRecords.csv')\n",
        "\n",
        "# Extract year using regex and convert to numeric, coercing errors\n",
        "olympics['Year'] = pd.to_numeric(olympics['Date'].str.extract(r'(\\d{4})')[0], errors='coerce')\n",
        "olympics['Time'] = olympics['Time'].astype(str).str.replace('[^\\d.]', '', regex=True)\n",
        "olympics['Time'] = pd.to_numeric(olympics['Time'], errors='coerce')\n",
        "\n",
        "men_data = olympics[olympics['Gender']==\"Men\"].groupby('Year').min().reset_index()\n",
        "\n",
        "# Drop rows with NaN values in Year or Time before fitting the model\n",
        "men_data = men_data.dropna(subset=['Year', 'Time'])\n",
        "\n",
        "# Ensure Year and Time columns are float type\n",
        "men_data['Year'] = men_data['Year'].astype(float)\n",
        "men_data['Time'] = men_data['Time'].astype(float)\n",
        "\n",
        "\n",
        "print(\"Shape of men_data before model fitting:\", men_data.shape)\n",
        "display(men_data)\n",
        "\n",
        "\n",
        "X = men_data[['Year']].values # Convert to NumPy array\n",
        "y = men_data['Time'].values # Convert to NumPy array\n",
        "\n",
        "lin_model = LinearRegression().fit(X, y)\n",
        "y_pred = lin_model.predict(X)\n",
        "\n",
        "plt.scatter(X, y, label=\"Actual\")\n",
        "plt.plot(X, y_pred, color=\"red\", label=\"Linear Trend\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Winning Time (s)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"R^2:\", r2_score(y, y_pred))"
      ],
      "metadata": {
        "id": "CH9tecjV-2ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions for 2024 and 2300\n"
      ],
      "metadata": {
        "id": "gCMxyUOz-4k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "future_years = np.array([[2024],[2300]])\n",
        "pred_times = lin_model.predict(future_years)\n",
        "print(\"Predicted Times:\", dict(zip(future_years.flatten(), pred_times)))"
      ],
      "metadata": {
        "id": "ZhYAJVXl-5Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f239150"
      },
      "source": [
        "print(\"Shape of men_data:\", men_data.shape)\n",
        "display(men_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion:**  \n",
        "- The linear model shows a steady decrease in sprint times.  \n",
        "- The prediction for 2024 is reasonable and close to current records.  \n",
        "- The prediction for 2300 is unrealistic because human physiology imposes limits. A non-linear asymptotic model (e.g., exponential decay or logistic curve) would likely be more valid long-term.  \n"
      ],
      "metadata": {
        "id": "WWxYrUIa-7MU"
      }
    }
  ]
}